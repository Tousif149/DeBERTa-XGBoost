{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11300743,"sourceType":"datasetVersion","datasetId":7067088}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:12:08.800945Z","iopub.execute_input":"2025-06-17T14:12:08.801301Z","iopub.status.idle":"2025-06-17T14:12:09.129135Z","shell.execute_reply.started":"2025-06-17T14:12:08.801270Z","shell.execute_reply":"2025-06-17T14:12:09.128390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === SECTION 0 — SETUP ===\n!pip install contractions\nimport contractions\nimport pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    accuracy_score, precision_recall_fscore_support, confusion_matrix,\n    classification_report, roc_auc_score, roc_curve, auc\n)\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport logging\nfrom torch.cuda.amp import autocast, GradScaler\nimport random\nimport os\nimport xgboost as xgb\nimport emoji\n\n# SEED for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# Logging\nlogging.basicConfig(level=logging.INFO, format='%(message)s')\nlogger = logging.getLogger()\n\n# Device setup\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnum_gpus = torch.cuda.device_count()\nprint(f\"Available GPUs: {num_gpus} (PyTorch)\")\n\n# === SECTION 1 — DATA LOADING, PREPROCESSING, SPLITS ===\n# Preprocessing functions\ndef remove_emojis(text):\n    return emoji.replace_emoji(text, replace='')\n\ndef preprocess_text(text):\n    if not isinstance(text, str) or not text.strip():\n        return \"\"\n    # Expand contractions first\n    text = contractions.fix(text)\n    text = remove_emojis(text)  # remove emojis \n    text = re.sub(r'http\\S+', '', text)              # remove URLs\n    text = re.sub(r'@\\w+', '', text)                 # remove mentions\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)       # remove special characters\n    text = text.lower().strip()                      # lowercase & strip\n    return text\n\n# Add label mapping function\ndef map_labels(labels):\n    label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n    return [label_map.get(l.lower(), 0) if isinstance(l, str) else l for l in labels]\n\n# Load data and detect label column\ndata = pd.read_csv('/kaggle/input/eda-augment/augmented_tweets.csv')\ndata['text'] = data['text'].apply(preprocess_text)\ndata = data[data['text'] != \"\"]  # filter out empty rows\n\n# Automatically detect label column (try 'airline_sentiment' first, then 'label')\nlabel_column = 'airline_sentiment' if 'airline_sentiment' in data.columns else 'label'\nprint(f\"Using label column: {label_column}\")\n\n# Map string labels to integers\ndata['label'] = map_labels(data[label_column].values)\n\n# Split\ntrain_val, test = train_test_split(data, test_size=0.2, random_state=SEED, stratify=data['label'])\ntrain, val = train_test_split(train_val, test_size=0.25, random_state=SEED, stratify=train_val['label'])\n\n# Prepare arrays with mapped labels\ntrain_texts = train['text'].values\ntrain_labels = train['label'].values\nval_texts   = val['text'].values\nval_labels  = val['label'].values\ntest_texts  = test['text'].values\ntest_labels = test['label'].values\n\n# No need to map labels — already 0, 1, 2\nprint(data['label'].value_counts(dropna=False))  # optional sanity check\n\n# === SECTION 2 — HYPERPARAMETERS ===\nmax_length = 128\nbatch_size = 32\nepochs = 7\npatience = 3\nlearning_rate = 2e-5\n\n# === UNIVERSAL EMBEDDING EXTRACT FUNCTION ===\ndef extract_embeddings(dataloader, encoder_model):\n    encoder_model.eval()\n    all_embeddings = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Extracting embeddings\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = encoder_model(input_ids=input_ids, attention_mask=attention_mask)\n            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token embedding\n            all_embeddings.append(cls_embeddings.cpu().numpy())\n            all_labels.append(labels.cpu().numpy())\n\n    embeddings = np.concatenate(all_embeddings, axis=0)\n    labels = np.concatenate(all_labels, axis=0)\n    return embeddings, labels\n\n# === SECTION 3 — DeBERTa-v3-large CLASSIFIER ===\n\n# Focal Loss\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1.0, gamma=1.5, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        return focal_loss\n\n# === TRAIN EPOCH ===\ndef train_epoch(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    for batch in tqdm(loader, desc=\"Training\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n\n        with autocast():\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            loss = criterion(logits, labels)\n\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item()\n        _, predicted = torch.max(logits, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    avg_loss = total_loss / len(loader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n\n# === EVALUATE EPOCH ===\ndef evaluate_epoch(model, loader, criterion):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Validating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            loss = criterion(logits, labels)\n\n            total_loss += loss.item()\n            _, predicted = torch.max(logits, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    avg_loss = total_loss / len(loader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n\n# === Tokenizer ===\ntokenizer_deberta = AutoTokenizer.from_pretrained('microsoft/deberta-v3-large')\n\n# === Dataset class ===\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = tokenizer_deberta(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=max_length,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'label': torch.tensor(label, dtype=torch.long),\n            'text': text\n        }\n\n# === Dataloaders ===\ntrain_dataset = SentimentDataset(train_texts, train_labels)\nval_dataset = SentimentDataset(val_texts, val_labels)\ntest_dataset = SentimentDataset(test_texts, test_labels)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# === Model ===\ndeberta_model = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-large', num_labels=3)\n\nif num_gpus > 1:\n    print(f\"Using {num_gpus} GPUs for PyTorch model\")\n    deberta_model = nn.DataParallel(deberta_model)\ndeberta_model.to(device)\n\n# === Optimizer, scheduler, loss, scaler ===\noptimizer = optim.NAdam(deberta_model.parameters(), lr=learning_rate)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\ncriterion = FocalLoss(alpha=1.0, gamma=1.5)\nscaler = GradScaler()\n\n# === Training loop ===\nbest_val_acc_deberta = 0.0\ncounter = 0\n\nprint(\"Training DeBERTa v3 Large model...\")\ntrain_accuracies_deberta = []\nval_accuracies_deberta = []\ntrain_losses_deberta = []\nval_losses_deberta = []\n\nfor epoch in range(epochs):\n    train_loss, train_acc = train_epoch(deberta_model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate_epoch(deberta_model, val_loader, criterion)\n\n    logger.info(f\"Epoch {epoch + 1}: \"\n                f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, \"\n                f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n\n    print(f\"==> Epoch {epoch+1}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n\n    train_accuracies_deberta.append(train_acc)\n    val_accuracies_deberta.append(val_acc)\n    train_losses_deberta.append(train_loss)\n    val_losses_deberta.append(val_loss)\n\n    scheduler.step()\n\n    # Save best model\n    if val_acc > best_val_acc_deberta:\n        best_val_acc_deberta = val_acc\n        counter = 0\n        torch.save(deberta_model.state_dict(), 'deberta_v3_large_model.pt')\n        print(\"✅ Saved best model to deberta_v3_large_model.pt\")\n    else:\n        counter += 1\n        if counter >= patience:\n            print(f\"Early stopping at epoch {epoch + 1}\")\n            break\n\n# === Save training/val stats ===\ndf_stats_deberta = pd.DataFrame({\n    'epoch': list(range(1, len(train_losses_deberta)+1)),\n    'train_loss': train_losses_deberta,\n    'val_loss': val_losses_deberta,\n    'train_accuracy': train_accuracies_deberta,\n    'val_accuracy': val_accuracies_deberta\n})\n\ndf_stats_deberta.to_csv('training_validation_stats_deberta.csv', index=False)\nprint(\"Training and validation stats saved to 'training_validation_stats_deberta.csv'.\")\n\n# === Final message ===\nprint(\"\\n✅ DeBERTa fine-tuning completed!\")\n\n# === DEBERTA CLASSIFICATION REPORT ===\n\n# Load best model\ndeberta_model.load_state_dict(torch.load('deberta_v3_large_model.pt'))\ndeberta_model.eval()\n\n# Predict on test set\ntest_predictions_deberta = []\ntest_true_labels_deberta = []\ndeberta_probs = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"DeBERTa Testing\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        outputs = deberta_model(input_ids=input_ids, attention_mask=attention_mask)\n        probs = nn.functional.softmax(outputs.logits, dim=1)\n        _, predicted = torch.max(probs, 1)\n\n        deberta_probs.extend(probs.cpu().numpy())\n        test_predictions_deberta.extend(predicted.cpu().numpy())\n        test_true_labels_deberta.extend(labels.cpu().numpy())\n\ndeberta_probs = np.array(deberta_probs)\n\n# === Report ===\nprint(\"\\n=== DeBERTa CLASSIFIER ===\")\nprint(\"\\nClassification Report:\")\nreport = classification_report(test_true_labels_deberta, test_predictions_deberta, target_names=['Negative', 'Neutral', 'Positive'], digits=4, output_dict=True)\nprint(classification_report(test_true_labels_deberta, test_predictions_deberta, target_names=['Negative', 'Neutral', 'Positive'], digits=4))\nprint(f\"\\nOverall Metrics:\")\nprint(f\"Accuracy: {report['accuracy']:.4f}\")\nprint(f\"Precision (macro): {report['macro avg']['precision']:.4f}\")\nprint(f\"Recall (macro): {report['macro avg']['recall']:.4f}\")\nprint(f\"F1-Score (macro): {report['macro avg']['f1-score']:.4f}\")\n\ncm_deberta = confusion_matrix(test_true_labels_deberta, test_predictions_deberta)\nprint(\"\\nConfusion Matrix:\")\nprint(cm_deberta)\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm_deberta, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Negative', 'Neutral', 'Positive'],\n            yticklabels=['Negative', 'Neutral', 'Positive'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('DeBERTa Classifier - Confusion Matrix')\nplt.show()\n\n# === SECTION 4: DeBERTa EMBEDDINGS → XGBoost ===\nprint(\"\\n=== SECTION 4: DeBERTa EMBEDDINGS → XGBoost ===\")\n\n# Use fine-tuned encoder\ndeberta_model.load_state_dict(torch.load('deberta_v3_large_model.pt'))\n\nif isinstance(deberta_model, nn.DataParallel):\n    deberta_encoder = deberta_model.module.deberta\nelse:\n    deberta_encoder = deberta_model.deberta\n\ndeberta_encoder.to(device)\n\n# Extract embeddings\ntrain_embeddings_deberta, train_labels_deberta = extract_embeddings(train_loader, deberta_encoder)\ntest_embeddings_deberta, test_labels_deberta = extract_embeddings(test_loader, deberta_encoder)\n\n# XGBoost on DeBERTa embeddings\nxgb_clf_deberta = xgb.XGBClassifier(\n    objective='multi:softmax',\n    num_class=3,\n    max_depth=6,\n    learning_rate=0.1,\n    n_estimators=300,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    seed=SEED,\n    verbosity=1,\n    n_jobs=-1\n)\n\nxgb_clf_deberta.fit(train_embeddings_deberta, train_labels_deberta)\nxgb_preds_deberta = xgb_clf_deberta.predict(test_embeddings_deberta)\nxgb_probs_deberta = xgb_clf_deberta.predict_proba(test_embeddings_deberta)\n\n# Report XGBoost results\nprint(\"\\n=== DeBERTa EMBEDDINGS + XGBoost CLASSIFIER ===\")\nprint(\"\\nClassification Report:\")\nreport = classification_report(test_labels_deberta, xgb_preds_deberta, target_names=['Negative', 'Neutral', 'Positive'], digits=4, output_dict=True)\nprint(classification_report(test_labels_deberta, xgb_preds_deberta, target_names=['Negative', 'Neutral', 'Positive'], digits=4))\nprint(f\"\\nOverall Metrics:\")\nprint(f\"Accuracy: {report['accuracy']:.4f}\")\nprint(f\"Precision (macro): {report['macro avg']['precision']:.4f}\")\nprint(f\"Recall (macro): {report['macro avg']['recall']:.4f}\")\nprint(f\"F1-Score (macro): {report['macro avg']['f1-score']:.4f}\")\n\ncm_xgb_deberta = confusion_matrix(test_labels_deberta, xgb_preds_deberta)\nprint(\"\\nConfusion Matrix:\")\nprint(cm_xgb_deberta)\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm_xgb_deberta, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Neutral', 'Positive'], yticklabels=['Negative', 'Neutral', 'Positive'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('DeBERTa Embeddings + XGBoost - Confusion Matrix')\nplt.show()\n\n# === SECTION 9: AUC Computation and Saving ===\n\n# Helper functions\ndef compute_auc(y_true, y_probs, num_classes=3):\n    aucs = []\n    y_true_bin = np.eye(num_classes)[y_true]\n    for i in range(num_classes):\n        auc_i = roc_auc_score(y_true_bin[:, i], y_probs[:, i])\n        aucs.append(auc_i)\n    macro_auc = np.mean(aucs)\n    return aucs, macro_auc\n\ndef plot_roc(y_true, y_probs, model_name, save_path=None):\n    num_classes = y_probs.shape[1]\n    y_true_bin = np.eye(num_classes)[y_true]\n    class_names = ['Negative', 'Neutral', 'Positive']\n\n    plt.figure(figsize=(8, 6))\n    for i in range(num_classes):\n        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.4f})')\n\n    plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC Curve - {model_name}')\n    plt.legend(loc='lower right')\n    plt.grid()\n\n    if save_path:\n        plt.savefig(save_path)\n    plt.show()\n\n# Initialize AUC summary dataframe\nauc_summary_df = pd.DataFrame(columns=['Model', 'Macro AUC', 'Class 0 AUC', 'Class 1 AUC', 'Class 2 AUC'])\n\n# === DeBERTa Softmax AUC ===\naucs_deberta_softmax, macro_auc_deberta_softmax = compute_auc(test_labels_deberta, deberta_probs)\nplot_roc(test_labels_deberta, deberta_probs, model_name='DeBERTa Softmax', save_path='deberta_softmax_roc.png')\nauc_summary_df.loc[len(auc_summary_df)] = ['DeBERTa Softmax', macro_auc_deberta_softmax] + aucs_deberta_softmax\n\n# === DeBERTa + XGBoost AUC ===\naucs_xgb_deberta, macro_auc_xgb_deberta = compute_auc(test_labels_deberta, xgb_probs_deberta)\nplot_roc(test_labels_deberta, xgb_probs_deberta, model_name='DeBERTa + XGBoost', save_path='deberta_xgb_roc.png')\nauc_summary_df.loc[len(auc_summary_df)] = ['DeBERTa + XGBoost', macro_auc_xgb_deberta] + aucs_xgb_deberta\n\n# === Save AUC Summary CSV ===\nauc_summary_df.to_csv('auc_summary_deberta_models.csv', index=False)\nprint(\"\\n✅ AUC summary saved to 'auc_summary_deberta_models.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T14:12:09.130461Z","iopub.execute_input":"2025-06-17T14:12:09.130848Z","execution_failed":"2025-06-17T14:12:13.896Z"}},"outputs":[],"execution_count":null}]}